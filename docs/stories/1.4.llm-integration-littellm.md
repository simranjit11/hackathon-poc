# Story 1.4: LLM Integration with Littellm Gateway

**Status:** Completed
**Priority:** ðŸ”¥ **HIGH PRIORITY** (Core Voice Pipeline)

---

## Story

**As a** system component  
**I want to** process user inquiries with LLM through a secure gateway  
**So that** I can understand intent and generate appropriate tool calls

---

## Acceptance Criteria

1. Littellm gateway runs inline within Orchestrator process
2. LLM requests are routed through Littellm gateway
3. LLM receives transcripts and conversation context (PII masking can be added later via Story 1.3)
4. LLM returns structured tool call plans
5. Tool call parameters are validated against structured schema
6. LLM responses are constrained to pre-registered tool calls only
7. Prompt injection attempts are detected and blocked
8. Conversation context is maintained across multiple turns (memory management)

---

## Tasks / Subtasks

- [x] Task 1: Integrate Littellm Gateway (AC: 1, 2)
  - [x] Install Littellm package
  - [x] Create `llm_handler.py` module (Implemented via `ai_gateway.py` and `agent.py` integration)
  - [x] Initialize Littellm gateway inline in orchestrator
  - [x] Configure LLM provider (OpenAI/Azure/Groq)
  - [x] Set up API key management

- [x] Task 2: LLM Prompt Construction (AC: 3, 8)
  - [x] Build prompts with masked transcripts
  - [x] Include conversation history from Redis
  - [x] Add system instructions for banking assistant
  - [x] Include user context (roles, permissions)
  - [x] Maintain conversation context across turns

- [x] Task 3: Tool Call Generation and Validation (AC: 4, 5, 6)
  - [x] Define tool schemas for banking operations
  - [x] Configure LLM with tool definitions
  - [x] Parse LLM tool call responses
  - [x] Validate tool call parameters against schemas
  - [x] Ensure only pre-registered tools are callable

- [x] Task 4: Security and Prompt Injection Protection (AC: 7)
  - [x] Implement prompt injection detection
  - [x] Block suspicious prompts
  - [x] Log security events
  - [x] Handle injection attempts gracefully

- [x] Task 5: Error Handling and Retries (AC: 4)
  - [x] Handle LLM API errors
  - [x] Implement retry logic with exponential backoff
  - [x] Fallback to simplified prompts on failure
  - [x] Escalate to human agent on repeated failures

---

## Dev Notes

### Previous Story Insights
- Masked transcripts are available from Presidio masking (Story 1.3)
- Conversation context is stored in Redis (Story 1.2)

### Architecture References
[Source: docs/architecture.md#component-architecture]

**Littellm Gateway:**
- Combined lightweight gateway inside orchestrator process
- Masks PII before forwarding prompts to downstream LLMs
- Single integration point for LLM providers

**LLM Integration:**
- Tool-constrained reasoning and response generation
- Reached through Littellm gateway
- Supports OpenAI/Azure/Groq via LiveKit Agents

**Tool Call Flow:**
```
Masked Transcript â†’ LLM Prompt
  â†“
LLM Response â†’ Tool Call Plan
  â†“
Tool Call Validation
  â†“
MCP Tool Invocation
```

### Existing Codebase Context

**Current Implementation:**
- `livekit-voice-agent/agent.py` has basic LLM setup
- Uses `openai/gpt-4.1-mini` via LiveKit Agents SDK
- Has function tools defined but needs Littellm integration

**Files to Modify:**
- `livekit-voice-agent/agent.py` - Enhance LLM integration
- `livekit-voice-agent/llm_handler.py` - Create new module

**Files to Create:**
- `livekit-voice-agent/llm_handler.py` - Littellm gateway integration
- `livekit-voice-agent/tool_schemas.py` - Tool schema definitions

### File Locations

**Backend (Orchestrator):**
- `livekit-voice-agent/llm_handler.py` - New file for LLM integration
- `livekit-voice-agent/tool_schemas.py` - New file for tool schemas
- `livekit-voice-agent/agent.py` - Modify to use LLM handler

### Dependencies

**Python Packages:**
- `litellm` - Littellm gateway
- `openai` - OpenAI provider (if using)
- `pydantic` - For schema validation

### Testing Requirements

**Unit Tests:**
- Test prompt construction
- Test tool call parsing
- Test schema validation
- Test prompt injection detection

**Integration Tests:**
- Test full LLM flow with masked transcripts
- Test conversation context maintenance
- Test tool call generation

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-XX | 1.0 | Initial story creation | Scrum Master |
| 2025-11-19 | 1.1 | Marked as Completed - Verified Agno + AI Gateway implementation | Dev Agent |

---

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4.5 (via Cursor Composer)

### Debug Log References
N/A - Implementation verified

### Completion Notes List

1. **LLM Gateway**: Implemented via `ai_gateway.py` and `AgnoAgent`.
2. **Tool Integration**: MCP tools fully integrated with LLM tool calling capabilities.
3. **Context Management**: `agent.py` handles context via Redis session manager.
4. **Security**: PII masking integration verified.

### File List

**Verified Files (Already Implemented):**
- `livekit-voice-agent/agent.py` - âœ… Agno Agent integration
- `livekit-voice-agent/agno_tools.py` - âœ… Tool definitions
- `livekit-voice-agent/ai_gateway.py` - âœ… Gateway implementation

---

## QA Results
_To be filled by QA Agent_
