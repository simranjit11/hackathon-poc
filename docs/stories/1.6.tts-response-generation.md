# Story 1.6: TTS Response Generation

**Status:** Draft  
**Priority:** ðŸ”¥ **HIGH PRIORITY** (Core Voice Pipeline)

---

## Story

**As a** banking customer  
**I want to** hear natural language responses to my inquiries  
**So that** I can understand my account information without reading

---

## Acceptance Criteria

1. Orchestrator formats MCP results into natural language narration
2. Narration includes summary of what was requested and key data points
3. TTS Engine (Cartesia/ElevenLabs) converts text to speech audio stream
4. Audio stream is sent to LiveKit for delivery to client
5. Client plays audio response to user
6. TTS errors are handled gracefully with fallback to text response
7. Audio quality meets minimum requirements for clear playback

---

## Tasks / Subtasks

- [ ] Task 1: Response Formatting (AC: 1, 2)
  - [ ] Create response formatter module
  - [ ] Format balance results into conversational language (e.g., "Your checking account has $2,547.83")
  - [ ] Format transaction history as natural sentences (e.g., "Sam transferred $20 to Simran, Simran transferred $20 to Sam...")
  - [ ] Limit transaction narration to 5 transactions per response
  - [ ] Add follow-up question after transactions: "Do you want me to tell you the next 5 transactions?"
  - [ ] Format loan information conversationally
  - [ ] Include contextual information naturally in narration
  - [ ] Ensure all narration sounds natural and conversational (not robotic lists)

- [ ] Task 2: TTS Engine Integration (AC: 3, 4)
  - [ ] Create `tts_handler.py` module
  - [ ] Integrate Cartesia TTS (or ElevenLabs)
  - [ ] Convert formatted text to speech audio
  - [ ] Stream audio to LiveKit room
  - [ ] Handle TTS API errors

- [ ] Task 3: Client Audio Playback (AC: 5)
  - [ ] Ensure LiveKit audio tracks are subscribed
  - [ ] Play audio response automatically
  - [ ] Handle audio playback errors
  - [ ] Show audio playback status in UI

- [ ] Task 4: Error Handling and Fallback (AC: 6)
  - [ ] Detect TTS failures
  - [ ] Fallback to text response display
  - [ ] Show user-friendly error messages
  - [ ] Log errors for debugging

---

## Dev Notes

### Previous Story Insights
- MCP tools return masked JSON results (Story 1.5)
- Results need to be formatted for voice narration
- Natural language formatting is detailed in Story 1.7

### Architecture References
[Source: docs/architecture.md#component-architecture]

**TTS Engine:**
- Cartesia / ElevenLabs
- Converts final JSON response to real-time speech
- Streamed via LiveKit

**Response Flow:**
```
MCP Result â†’ Orchestrator
  â†“
Result Formatting
  â†“
TTS Engine
  â†“
Audio Stream â†’ LiveKit
  â†“
Client Audio Playback
```

### Existing Codebase Context

**Current Implementation:**
- `livekit-voice-agent/agent.py` uses `cartesia/sonic-3` for TTS
- TTS is handled by LiveKit Agents SDK
- Need to enhance response formatting

**Files to Create:**
- `livekit-voice-agent/tts_handler.py` - TTS integration
- `livekit-voice-agent/response_formatter.py` - Response formatting (see Story 1.7 for detailed formatting requirements)

**Files to Modify:**
- `livekit-voice-agent/agent.py` - Enhance TTS handling

### File Locations

**Backend (Orchestrator):**
- `livekit-voice-agent/tts_handler.py` - New file
- `livekit-voice-agent/response_formatter.py` - New file

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-XX | 1.0 | Initial story creation | Scrum Master |

---

## Dev Agent Record

### Agent Model Used
_To be filled by Dev Agent_

### Debug Log References
_To be filled by Dev Agent_

### Completion Notes List
_To be filled by Dev Agent_

### File List
_To be filled by Dev Agent_

---

## QA Results
_To be filled by QA Agent_

